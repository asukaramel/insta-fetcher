import requests
import os
import csv
import datetime
import urllib.request
import gspread
import re
import logging
from oauth2client.service_account import ServiceAccountCredentials
import schedule
import time
from datetime import datetime as dt
import pytz
import traceback

from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload


# ====== è¨­å®šé …ç›® ======
HASHTAG = 'å¾³å·åœ’'
INSTAGRAM_BUSINESS_ID = '17841413261363491'
ACCESS_TOKEN = os.getenv('ACCESS_TOKEN')
SAVE_DIR = 'images'  # ãƒ­ãƒ¼ã‚«ãƒ«ã®ä¿å­˜ãƒ‘ã‚¹
CSV_PATH = 'log.csv'
SPREADSHEET_NAME = 'InstaContestLog'
GOOGLE_CREDENTIALS_PATH = 'client_secret.json'  # èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
SLACK_WEBHOOK_URL = os.getenv('SLACK_WEBHOOK_URL')  # â† ã‚ãªãŸã®Slack Webhook URLã«ã™ã‚‹
DRIVE_FOLDER_ID ='1YGx-G-5eMxrEinVBleYvMvYqsS5DIYaL'
# =======================

# âœ… ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    filename='log.txt',
    filemode='a',
    level=logging.INFO,
    format='%(asctime)s - %(message)s',
)

def log(message):
    print(message)
    logging.info(message)

# âœ… Slacké€šçŸ¥
def notify_slack(message):
    payload = {'text': message}
    try:
        response = requests.post(SLACK_WEBHOOK_URL, json=payload)
        if response.status_code != 200:
            log(f"Slacké€šçŸ¥ã‚¨ãƒ©ãƒ¼: {response.status_code} {response.text}")
    except Exception as e:
        log(f"Slacké€šçŸ¥ä¾‹å¤–: {e}")

# ï¼ˆä»¥é™ã¯åŒã˜ï¼‰
# Google Sheets èªè¨¼
def get_gspread_client():
    scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
    creds = ServiceAccountCredentials.from_json_keyfile_name(GOOGLE_CREDENTIALS_PATH, scope)
    return gspread.authorize(creds)

# Instagram APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ
def instagram_api(url):
    headers = {'Authorization': f'Bearer {ACCESS_TOKEN}'}
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.HTTPError as e:
        log(f"HTTP Error {response.status_code} : {response.text}")
        raise
    except Exception as e:
        log(f"Unexpected error: {e}")
        raise

# ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°IDã‚’å–å¾—
def get_hashtag_id():
    url = f"https://graph.facebook.com/v23.0/ig_hashtag_search?user_id={INSTAGRAM_BUSINESS_ID}&q={HASHTAG}&access_token={ACCESS_TOKEN}"
    data = instagram_api(url)
    hashtag_id = data['data'][0]['id']
    log(f"Hashtag ID for '{HASHTAG}' is {hashtag_id}")
    return hashtag_id


# æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ã‚’å…¨ä»¶å–å¾—ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œï¼‰
def fetch_posts():
    hashtag_id = get_hashtag_id()
    url = (
        f"https://graph.facebook.com/v23.0/{hashtag_id}/recent_media"
        f"?user_id={INSTAGRAM_BUSINESS_ID}&fields=id,timestamp,media_url,like_count,comments_count,permalink,caption"
        f"&limit=50&access_token={ACCESS_TOKEN}"
    )
    posts = []
    while url:
        data = instagram_api(url)
        posts.extend(data['data'])
        url = data.get('paging', {}).get('next')
        time.sleep(1)  # â† ã“ã“ã§1ç§’å¾…ã¤ï¼ˆå¿…è¦ã«å¿œã˜ã¦ç§’æ•°èª¿æ•´ï¼‰
    return posts

# ç”»åƒã‚’ä¿å­˜
def download_image(url, path):
    urllib.request.urlretrieve(url, path)

# Google Drive ã«ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰


def upload_to_drive(file_path, file_name, drive_folder_id):
    try:
        # Drive API ç”¨ã®èªè¨¼
        scopes = ['https://www.googleapis.com/auth/drive']
        creds = service_account.Credentials.from_service_account_file(GOOGLE_CREDENTIALS_PATH, scopes=scopes)
        service = build('drive', 'v3', credentials=creds)

        file_metadata = {
            'name': file_name,
            'parents': [drive_folder_id]  # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å…ˆãƒ•ã‚©ãƒ«ãƒ€ID
        }
        media = MediaFileUpload(file_path, mimetype='image/jpeg')
        uploaded_file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()

        log(f"â†’ Google Drive ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {file_name} (File ID: {uploaded_file.get('id')})")

    except Exception as e:
        log(f"Google Drive ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")


def load_existing_ids():
    if not os.path.exists(CSV_PATH):
        return set()
    with open(CSV_PATH, newline='', encoding='utf-8') as f:
        reader = csv.reader(f)
        next(reader)  # ãƒ˜ãƒƒãƒ€ãƒ¼èª­ã¿é£›ã°ã—
        return set(row[1] for row in reader)



# CSV ã«ä¿å­˜
def save_to_csv(post, file_name, timestamp_str,fetch_time):
    is_new = not os.path.exists(CSV_PATH)
    with open(CSV_PATH, 'a', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        if is_new:
            writer.writerow(['fetch_time','timestamp', 'id', 'filename', 'like_count', 'comment_count', 'caption', 'permalink', 'media_url'])
        writer.writerow([
            fetch_time,
            timestamp_str,
            post['id'],
            file_name,
            post.get('like_count', 0),
            post.get('comments_count', 0),
            post.get('caption', ''),
            post['permalink'],
            post['media_url'],
        ])

# Google ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜
def save_to_gsheet(post, file_name, timestamp_str, sheet, fetch_time):
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒãªã‘ã‚Œã°è¿½åŠ ï¼ˆfetch_timeã‚’å…ˆé ­ã«ï¼‰
    if sheet.row_count == 0 or sheet.cell(1, 1).value is None:
        sheet.append_row(['fetch_time', 'timestamp', 'id', 'filename', 'like_count', 'comment_count', 'caption', 'permalink', 'media_url'])

    sheet.append_row([
        fetch_time,
        timestamp_str,
        post['id'],
        file_name,
        post.get('like_count', 0),
        post.get('comments_count', 0),
        post.get('caption', ''),
        post['permalink'],
        post['media_url'],
    ])
    log(f"â†’ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜: {post['id']}")


# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ååˆ—ï¼ˆ4åˆ—ç›®ï¼‰ã‹ã‚‰æœ€å¤§ç•ªå·ã‚’å–å¾—
def get_next_file_number(sheet):
    try:
        filenames = sheet.col_values(4)[1:]  # 1è¡Œç›®ã¯ãƒ˜ãƒƒãƒ€ãƒ¼ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—
        numbers = []
        for name in filenames:
            match = re.match(r'tokugawa_(\d+)\.jpeg', name)
            if match:
                numbers.append(int(match.group(1)))
        return max(numbers) + 1 if numbers else 1
    except Exception as e:
        log(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åå–å¾—å¤±æ•—: {e}")
        return 1


# ãƒ¡ã‚¤ãƒ³å‡¦ç†
def job():
    log("===== ã‚¸ãƒ§ãƒ–é–‹å§‹ =====")
    retries = 3
    delay_sec = 10
    for attempt in range(1, retries+1):
        try:
            os.makedirs(SAVE_DIR, exist_ok=True)
            existing_ids = load_existing_ids()
            posts = fetch_posts()

            gc = get_gspread_client()
            sheet = gc.open(SPREADSHEET_NAME).sheet1
            existing_ids_gsheet = sheet.col_values(3)[1:]

            file_counter = get_next_file_number(sheet)
            jst = pytz.timezone('Asia/Tokyo')
            fetch_time = dt.now(tz=jst).strftime('%Y-%m-%d %H:%M:%S')

            new_count = 0
            for post in posts:
                if post['id'] in existing_ids or post['id'] in existing_ids_gsheet:
                    continue

                timestamp_utc = dt.strptime(post['timestamp'], '%Y-%m-%dT%H:%M:%S%z')
                timestamp_jst = timestamp_utc.astimezone(jst)
                timestamp_str = timestamp_jst.strftime('%Y-%m-%d %H:%M:%S')

                file_name = f'tokugawa_{file_counter}.jpeg'
                file_counter += 1

                image_path = os.path.join(SAVE_DIR, file_name)
                download_image(post['media_url'], image_path)

                save_to_csv(post, file_name, timestamp_str, fetch_time)
                save_to_gsheet(post, file_name, timestamp_str, sheet, fetch_time)
                upload_to_drive(image_path, file_name, DRIVE_FOLDER_ID)

                log(f"[NEW] {post['id']} â†’ {file_name}")
                new_count += 1

            log(f"===== ã‚¸ãƒ§ãƒ–çµ‚äº†: æ–°è¦å–å¾— {new_count} ä»¶ =====")
            notify_slack(f"âœ… Instagram Fetcher å®Œäº†ï¼ æ–°è¦å–å¾— {new_count} ä»¶ ( {dt.now().strftime('%Y-%m-%d %H:%M:%S')} )")
            break  # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—æŠœã‘ã‚‹

        except Exception as e:
            log(f"Attempt {attempt} failed: {e}")
            if attempt == retries:
                notify_slack(f"âŒ Instagram Fetcher ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ˆæœ€çµ‚è©¦è¡Œå¤±æ•—ï¼‰: {e}")
                log("æœ€å¤§è©¦è¡Œå›æ•°ã«é”ã—ã¾ã—ãŸã€‚å‡¦ç†ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                raise
            else:
                notify_slack(f"âš ï¸ Instagram Fetcher ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ˆè©¦è¡Œ {attempt}ï¼‰: {e}ã€‚{delay_sec}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™ã€‚")
                time.sleep(delay_sec)


# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼å®Ÿè¡Œ
schedule.every(6).hours.do(job)

if __name__ == "__main__":
    log("Instagram Fetcher started. Press Ctrl+C to stop.")
    notify_slack("ğŸš€ Instagram Fetcher èµ·å‹•ã—ã¾ã—ãŸï¼")
    job()  # æœ€åˆã«ä¸€åº¦å®Ÿè¡Œ
    while True:
        schedule.run_pending()
        time.sleep(60)